{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JKtnQ7Y1_J30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JKtnQ7Y1_J30",
        "outputId": "5622ec89-8fa9-4d08-ca2d-8816ac5a68fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.1\n",
            "  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 portalocker-3.2.0 torch-2.3.1 torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.3.1 torchtext==0.18.0 portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AdByqGW3ZAXZ",
      "metadata": {
        "collapsed": true,
        "id": "AdByqGW3ZAXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bacfa7-522d-4075-b880-67aeff4d1a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'NLP'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 192 (delta 62), reused 62 (delta 27), pack-reused 72 (from 1)\u001b[K\n",
            "Receiving objects: 100% (192/192), 51.16 MiB | 35.45 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone  https://github.com/NgThanhNhanf/NLP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739bf4d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "739bf4d4",
        "outputId": "644d8828-c31c-4b0f-c25c-31bb483f2409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59a600a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b59a600a",
        "outputId": "bd95f4c2-8d27-420f-8093-1f1c59ed9106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05afd97",
      "metadata": {
        "id": "e05afd97"
      },
      "source": [
        "After downloading, you can re-run the initialization cell (`b2bf295b`) to confirm that Spacy loads the models correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mJo_QEZ3eFc-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJo_QEZ3eFc-",
        "outputId": "a6204058-4f6c-4493-b51b-161536bac741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP\n"
          ]
        }
      ],
      "source": [
        "%cd /content/NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beKp8unreKcq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "beKp8unreKcq",
        "outputId": "7f5ac0ea-ce32-41e3-9f07-e95613082e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.3.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.8.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.12.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (5.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.8.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (4.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.14)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (2.0.1)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37P1IFku9Uew",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37P1IFku9Uew",
        "outputId": "397b8bc2-8b3b-4902-ad96-079eb714d54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thiết bị đang sử dụng: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from src.model_base import Encoder, Decoder, Seq2Seq\n",
        "from src.model_attention import EncoderAttention, DecoderAttention, Seq2SeqAttention\n",
        "from src.dataset import get_data_loaders, build_vocab_and_tokenizers\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Kiểm tra GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Thiết bị đang sử dụng: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PIP0WfvnNYrC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIP0WfvnNYrC",
        "outputId": "ce528528-9633-487c-b401-cf03483bafcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang xử lý dữ liệu...\n",
            "Đang xây dựng từ điển (Vocabulary)...\n",
            "Đang tạo Dataset...\n",
            "Đang tạo DataLoader...\n",
            "Số lượng câu Train: 29024\n",
            "Kích thước từ điển Anh: 5893\n",
            "Kích thước từ điển Pháp: 6471\n"
          ]
        }
      ],
      "source": [
        "print(\"Đang xử lý dữ liệu...\")\n",
        "\n",
        "# 1. Đường dẫn file (Đảm bảo bạn đã đổi tên file thành test.en, test.fr như mình dặn)\n",
        "SRC_FILE = 'data/raw/train.en'\n",
        "TRG_FILE = 'data/raw/train.fr'\n",
        "\n",
        "# 2. Xây dựng Vocab & Tokenizer\n",
        "src_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "trg_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "\n",
        "src_vocab, trg_vocab = build_vocab_and_tokenizers(src_tokenizer, trg_tokenizer)\n",
        "\n",
        "# 3. Tạo Iterators (DataLoaders)\n",
        "BATCH_SIZE = 32\n",
        "train_iterator, valid_iterator, test_iterator = get_data_loaders(batch_size=BATCH_SIZE, en_tokenizer = src_tokenizer, fr_tokenizer = trg_tokenizer,\n",
        "                                                                 src_vocab = src_vocab,  trg_vocab = trg_vocab)\n",
        "\n",
        "print(f\"Số lượng câu Train: {len(train_iterator) * BATCH_SIZE}\")\n",
        "print(f\"Kích thước từ điển Anh: {len(src_vocab)}\")\n",
        "print(f\"Kích thước từ điển Pháp: {len(trg_vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem bên trong từ điển\n",
        "src_vocab.get_itos()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCsEwi2WN4V5",
        "outputId": "f072a55d-9561-4566-d211-601f3d13cab3"
      },
      "id": "kCsEwi2WN4V5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<sos>', '<eos>', 'a', '.', 'in', 'the', 'on', 'man']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v9_gXicKOdIi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9_gXicKOdIi",
        "outputId": "9969dfef-eb10-481c-dfd3-f112874fa0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mô hình có 22,941,511 tham số có thể huấn luyện\n"
          ]
        }
      ],
      "source": [
        "# --- HYPERPARAMETERS ---\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(trg_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# --- KHỞI TẠO ---\n",
        "enc = EncoderAttention(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = DecoderAttention(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2SeqAttention(enc, dec, device).to(device)\n",
        "\n",
        "# --- KHỞI TẠO TRỌNG SỐ (WEIGHTS) ---\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Mô hình có {count_parameters(model):,} tham số có thể huấn luyện')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bkmb9HQOjGT",
      "metadata": {
        "id": "8bkmb9HQOjGT"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# Bỏ qua padding token khi tính loss\n",
        "TRG_PAD_IDX = trg_vocab['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3lg93jLsOm_L",
      "metadata": {
        "id": "3lg93jLsOm_L"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer,\n",
        "                        num_epochs, device, clip=1.0, teacher_forcing_ratio=0.5,\n",
        "                        patience=3, model_path='best_model.pth'):\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"Bắt đầu training với {num_epochs} epochs\")\n",
        "    print(f\"Teacher forcing ratio: {teacher_forcing_ratio}\")\n",
        "    print(f\"Gradient clip: {clip}\")\n",
        "    print(f\"Early stopping patience: {patience}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # === TRAINING PHASE ===\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Progress bar\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs} - Training...\")\n",
        "\n",
        "        for batch_idx, (source, target, source_lengths) in enumerate(train_loader):\n",
        "            source, target = source.to(device), target.to(device)\n",
        "            source_lengths = source_lengths.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward với teacher forcing\n",
        "            output = model(source, target, source_lengths, teacher_forcing_ratio)\n",
        "\n",
        "            # Tính loss\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            target = target[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping với tham số\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "            # In progress mỗi 50 batch\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"   Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / batch_count\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # === VALIDATION PHASE ===\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Validating...\")\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        batch_count_val = 0\n",
        "\n",
        "        # Lấy một batch từ DataLoader\n",
        "        batch = next(iter(val_loader))\n",
        "\n",
        "        print(f\"Số phần tử trong batch: {len(batch)}\")\n",
        "        print(f\"Kiểu dữ liệu batch: {type(batch)}\")\n",
        "\n",
        "        # Kiểm tra từng phần tử\n",
        "        for i, item in enumerate(batch):\n",
        "            print(f\"  Phần tử {i}: type={type(item)}, shape={item.shape if hasattr(item, 'shape') else len(item)}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for source, target, source_lengths in val_loader:\n",
        "                source, target = source.to(device), target.to(device)\n",
        "\n",
        "                # Evaluation: teacher forcing = 0\n",
        "                output = model(source, target, source_lengths, teacher_forcing_ratio=0)\n",
        "\n",
        "                output_dim = output.shape[-1]\n",
        "                output = output[:, 1:].reshape(-1, output_dim)\n",
        "                target = target[:, 1:].reshape(-1)\n",
        "\n",
        "                loss = criterion(output, target)\n",
        "                epoch_val_loss += loss.item()\n",
        "                batch_count_val += 1\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / batch_count_val\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # === IN KẾT QUẢ ===\n",
        "        print(f\"\\n Epoch {epoch+1} Summary:\")\n",
        "        print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
        "        print(f\"   Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # === EARLY STOPPING & SAVE BEST MODEL ===\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "            }, model_path)\n",
        "            print(f\"   Best model saved! (Loss: {avg_val_loss:.4f})\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"   No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs!\")\n",
        "                print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    print(f\"\\n Training completed!\")\n",
        "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "    print(f\"Total epochs trained: {len(train_losses)}\")\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8WLff0_OoI7",
      "metadata": {
        "id": "M8WLff0_OoI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5341950d-c030-4540-af82-f07f2e047b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu training với 15 epochs\n",
            "Teacher forcing ratio: 0.5\n",
            "Gradient clip: 1\n",
            "Early stopping patience: 3\n",
            "============================================================\n",
            "\n",
            "Epoch 1/15 - Training...\n",
            "   Batch 0/907, Loss: 8.7694\n",
            "   Batch 50/907, Loss: 5.1366\n",
            "   Batch 100/907, Loss: 5.0474\n",
            "   Batch 150/907, Loss: 4.9315\n",
            "   Batch 200/907, Loss: 5.0107\n",
            "   Batch 250/907, Loss: 4.8588\n",
            "   Batch 300/907, Loss: 4.8253\n",
            "   Batch 350/907, Loss: 4.4770\n",
            "   Batch 400/907, Loss: 4.7903\n",
            "   Batch 450/907, Loss: 4.3437\n",
            "   Batch 500/907, Loss: 4.6882\n",
            "   Batch 550/907, Loss: 4.3040\n",
            "   Batch 600/907, Loss: 4.0818\n",
            "   Batch 650/907, Loss: 4.4471\n",
            "   Batch 700/907, Loss: 4.1738\n",
            "   Batch 750/907, Loss: 4.2970\n",
            "   Batch 800/907, Loss: 4.2492\n",
            "   Batch 850/907, Loss: 3.8337\n",
            "   Batch 900/907, Loss: 4.0845\n",
            "Epoch 1/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 1 Summary:\n",
            "   Train Loss: 4.6343\n",
            "   Val Loss:   4.4651\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 4.4651)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 2/15 - Training...\n",
            "   Batch 0/907, Loss: 4.2143\n",
            "   Batch 50/907, Loss: 3.9876\n",
            "   Batch 100/907, Loss: 3.7895\n",
            "   Batch 150/907, Loss: 4.3324\n",
            "   Batch 200/907, Loss: 3.9571\n",
            "   Batch 250/907, Loss: 3.8649\n",
            "   Batch 300/907, Loss: 3.9802\n",
            "   Batch 350/907, Loss: 3.4360\n",
            "   Batch 400/907, Loss: 3.7600\n",
            "   Batch 450/907, Loss: 3.5443\n",
            "   Batch 500/907, Loss: 3.4613\n",
            "   Batch 550/907, Loss: 3.7046\n",
            "   Batch 600/907, Loss: 3.4437\n",
            "   Batch 650/907, Loss: 3.2256\n",
            "   Batch 700/907, Loss: 3.5627\n",
            "   Batch 750/907, Loss: 3.1707\n",
            "   Batch 800/907, Loss: 3.3165\n",
            "   Batch 850/907, Loss: 3.5772\n",
            "   Batch 900/907, Loss: 3.2830\n",
            "Epoch 2/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 2 Summary:\n",
            "   Train Loss: 3.6919\n",
            "   Val Loss:   3.8764\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.8764)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 3/15 - Training...\n",
            "   Batch 0/907, Loss: 3.0312\n",
            "   Batch 50/907, Loss: 3.1735\n",
            "   Batch 100/907, Loss: 3.1449\n",
            "   Batch 150/907, Loss: 3.1494\n",
            "   Batch 200/907, Loss: 3.0892\n",
            "   Batch 250/907, Loss: 2.9958\n",
            "   Batch 300/907, Loss: 3.1416\n",
            "   Batch 350/907, Loss: 2.5672\n",
            "   Batch 400/907, Loss: 2.6772\n",
            "   Batch 450/907, Loss: 2.8708\n",
            "   Batch 500/907, Loss: 3.0988\n",
            "   Batch 550/907, Loss: 2.7805\n",
            "   Batch 600/907, Loss: 2.7505\n",
            "   Batch 650/907, Loss: 2.9147\n",
            "   Batch 700/907, Loss: 2.8258\n",
            "   Batch 750/907, Loss: 3.1254\n",
            "   Batch 800/907, Loss: 2.5403\n",
            "   Batch 850/907, Loss: 3.0029\n",
            "   Batch 900/907, Loss: 3.4692\n",
            "Epoch 3/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 3 Summary:\n",
            "   Train Loss: 2.9879\n",
            "   Val Loss:   3.4445\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.4445)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 4/15 - Training...\n",
            "   Batch 0/907, Loss: 2.4317\n",
            "   Batch 50/907, Loss: 1.8670\n",
            "   Batch 100/907, Loss: 3.1766\n",
            "   Batch 150/907, Loss: 2.5144\n",
            "   Batch 200/907, Loss: 2.8211\n",
            "   Batch 250/907, Loss: 2.4465\n",
            "   Batch 300/907, Loss: 2.2778\n",
            "   Batch 350/907, Loss: 2.4804\n",
            "   Batch 400/907, Loss: 2.3236\n",
            "   Batch 450/907, Loss: 2.7687\n",
            "   Batch 500/907, Loss: 2.6416\n",
            "   Batch 550/907, Loss: 2.6171\n",
            "   Batch 600/907, Loss: 2.7235\n",
            "   Batch 650/907, Loss: 2.5202\n",
            "   Batch 700/907, Loss: 2.2834\n",
            "   Batch 750/907, Loss: 2.5073\n",
            "   Batch 800/907, Loss: 2.4257\n",
            "   Batch 850/907, Loss: 2.8898\n",
            "   Batch 900/907, Loss: 2.4336\n",
            "Epoch 4/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 4 Summary:\n",
            "   Train Loss: 2.5612\n",
            "   Val Loss:   3.2595\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.2595)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 5/15 - Training...\n",
            "   Batch 0/907, Loss: 2.3439\n",
            "   Batch 50/907, Loss: 2.5987\n",
            "   Batch 100/907, Loss: 2.2165\n",
            "   Batch 150/907, Loss: 2.5690\n",
            "   Batch 200/907, Loss: 2.1174\n",
            "   Batch 250/907, Loss: 2.5371\n",
            "   Batch 300/907, Loss: 2.3254\n",
            "   Batch 350/907, Loss: 2.2831\n",
            "   Batch 400/907, Loss: 2.1288\n",
            "   Batch 450/907, Loss: 2.6579\n",
            "   Batch 500/907, Loss: 2.0861\n",
            "   Batch 550/907, Loss: 2.0939\n",
            "   Batch 600/907, Loss: 2.1841\n",
            "   Batch 650/907, Loss: 2.2119\n",
            "   Batch 700/907, Loss: 2.0035\n",
            "   Batch 750/907, Loss: 2.4755\n",
            "   Batch 800/907, Loss: 1.8035\n",
            "   Batch 850/907, Loss: 2.3306\n",
            "   Batch 900/907, Loss: 1.8529\n",
            "Epoch 5/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 5 Summary:\n",
            "   Train Loss: 2.2642\n",
            "   Val Loss:   3.1266\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.1266)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 6/15 - Training...\n",
            "   Batch 0/907, Loss: 1.9396\n",
            "   Batch 50/907, Loss: 1.8882\n",
            "   Batch 100/907, Loss: 1.8980\n",
            "   Batch 150/907, Loss: 2.1882\n",
            "   Batch 200/907, Loss: 1.8421\n",
            "   Batch 250/907, Loss: 2.3046\n",
            "   Batch 300/907, Loss: 2.0038\n",
            "   Batch 350/907, Loss: 2.3192\n",
            "   Batch 400/907, Loss: 1.8889\n",
            "   Batch 450/907, Loss: 1.9972\n",
            "   Batch 500/907, Loss: 2.1996\n",
            "   Batch 550/907, Loss: 1.9150\n",
            "   Batch 600/907, Loss: 2.2910\n",
            "   Batch 650/907, Loss: 2.0242\n",
            "   Batch 700/907, Loss: 2.0920\n",
            "   Batch 750/907, Loss: 1.8435\n",
            "   Batch 800/907, Loss: 1.6201\n",
            "   Batch 850/907, Loss: 2.1943\n",
            "   Batch 900/907, Loss: 1.8855\n",
            "Epoch 6/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 6 Summary:\n",
            "   Train Loss: 2.0360\n",
            "   Val Loss:   3.0624\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0624)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 7/15 - Training...\n",
            "   Batch 0/907, Loss: 1.8350\n",
            "   Batch 50/907, Loss: 1.8977\n",
            "   Batch 100/907, Loss: 1.6818\n",
            "   Batch 150/907, Loss: 1.4921\n",
            "   Batch 200/907, Loss: 2.0872\n",
            "   Batch 250/907, Loss: 1.7615\n",
            "   Batch 300/907, Loss: 2.2586\n",
            "   Batch 350/907, Loss: 1.6856\n",
            "   Batch 400/907, Loss: 1.9147\n",
            "   Batch 450/907, Loss: 1.9337\n",
            "   Batch 500/907, Loss: 1.8860\n",
            "   Batch 550/907, Loss: 2.0330\n",
            "   Batch 600/907, Loss: 1.8536\n",
            "   Batch 650/907, Loss: 2.1664\n",
            "   Batch 700/907, Loss: 2.1076\n",
            "   Batch 750/907, Loss: 1.7419\n",
            "   Batch 800/907, Loss: 1.7504\n",
            "   Batch 850/907, Loss: 1.9535\n",
            "   Batch 900/907, Loss: 1.6237\n",
            "Epoch 7/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 7 Summary:\n",
            "   Train Loss: 1.8698\n",
            "   Val Loss:   3.0581\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0581)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 8/15 - Training...\n",
            "   Batch 0/907, Loss: 1.7865\n",
            "   Batch 50/907, Loss: 1.6491\n",
            "   Batch 100/907, Loss: 1.9286\n",
            "   Batch 150/907, Loss: 1.7504\n",
            "   Batch 200/907, Loss: 1.6620\n",
            "   Batch 250/907, Loss: 1.4713\n",
            "   Batch 300/907, Loss: 1.8336\n",
            "   Batch 350/907, Loss: 2.2059\n",
            "   Batch 400/907, Loss: 1.6135\n",
            "   Batch 450/907, Loss: 1.1447\n",
            "   Batch 500/907, Loss: 1.5838\n",
            "   Batch 550/907, Loss: 1.5725\n",
            "   Batch 600/907, Loss: 1.5978\n",
            "   Batch 650/907, Loss: 1.8129\n",
            "   Batch 700/907, Loss: 1.7718\n",
            "   Batch 750/907, Loss: 1.5277\n",
            "   Batch 800/907, Loss: 1.4868\n",
            "   Batch 850/907, Loss: 1.6903\n",
            "   Batch 900/907, Loss: 1.5934\n",
            "Epoch 8/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 8 Summary:\n",
            "   Train Loss: 1.7269\n",
            "   Val Loss:   3.0465\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0465)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 9/15 - Training...\n",
            "   Batch 0/907, Loss: 1.7229\n",
            "   Batch 50/907, Loss: 1.1570\n",
            "   Batch 100/907, Loss: 1.3194\n",
            "   Batch 150/907, Loss: 1.5665\n",
            "   Batch 200/907, Loss: 1.5475\n",
            "   Batch 250/907, Loss: 1.6328\n",
            "   Batch 300/907, Loss: 1.4216\n",
            "   Batch 350/907, Loss: 1.7931\n",
            "   Batch 400/907, Loss: 1.5724\n",
            "   Batch 450/907, Loss: 1.4918\n",
            "   Batch 500/907, Loss: 1.7452\n",
            "   Batch 550/907, Loss: 1.7650\n",
            "   Batch 600/907, Loss: 1.8250\n",
            "   Batch 650/907, Loss: 1.8414\n",
            "   Batch 700/907, Loss: 1.2837\n",
            "   Batch 750/907, Loss: 1.3787\n",
            "   Batch 800/907, Loss: 1.7836\n",
            "   Batch 850/907, Loss: 1.4676\n",
            "   Batch 900/907, Loss: 2.2406\n",
            "Epoch 9/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 9 Summary:\n",
            "   Train Loss: 1.5916\n",
            "   Val Loss:   3.0078\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0078)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 10/15 - Training...\n",
            "   Batch 0/907, Loss: 1.2332\n",
            "   Batch 50/907, Loss: 1.5194\n",
            "   Batch 100/907, Loss: 1.3976\n",
            "   Batch 150/907, Loss: 1.7641\n",
            "   Batch 200/907, Loss: 2.0566\n",
            "   Batch 250/907, Loss: 1.3821\n",
            "   Batch 300/907, Loss: 1.5776\n",
            "   Batch 350/907, Loss: 1.4682\n",
            "   Batch 400/907, Loss: 1.2699\n",
            "   Batch 450/907, Loss: 1.3959\n",
            "   Batch 500/907, Loss: 1.2963\n",
            "   Batch 550/907, Loss: 1.2680\n",
            "   Batch 600/907, Loss: 1.7015\n",
            "   Batch 650/907, Loss: 1.8726\n",
            "   Batch 700/907, Loss: 1.2101\n",
            "   Batch 750/907, Loss: 1.7194\n",
            "   Batch 800/907, Loss: 1.1712\n",
            "   Batch 850/907, Loss: 1.1924\n",
            "   Batch 900/907, Loss: 1.3789\n",
            "Epoch 10/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 10 Summary:\n",
            "   Train Loss: 1.4724\n",
            "   Val Loss:   3.0186\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 11/15 - Training...\n",
            "   Batch 0/907, Loss: 1.8154\n",
            "   Batch 50/907, Loss: 1.5835\n",
            "   Batch 100/907, Loss: 1.4032\n",
            "   Batch 150/907, Loss: 1.2356\n",
            "   Batch 200/907, Loss: 1.2981\n",
            "   Batch 250/907, Loss: 1.0523\n",
            "   Batch 300/907, Loss: 1.3015\n",
            "   Batch 350/907, Loss: 1.1704\n",
            "   Batch 400/907, Loss: 1.4452\n",
            "   Batch 450/907, Loss: 1.3428\n",
            "   Batch 500/907, Loss: 1.4398\n",
            "   Batch 550/907, Loss: 1.4392\n",
            "   Batch 600/907, Loss: 1.5525\n",
            "   Batch 650/907, Loss: 1.2851\n",
            "   Batch 700/907, Loss: 1.2940\n",
            "   Batch 750/907, Loss: 1.3929\n",
            "   Batch 800/907, Loss: 1.7412\n",
            "   Batch 850/907, Loss: 1.4694\n",
            "   Batch 900/907, Loss: 2.2452\n",
            "Epoch 11/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 11 Summary:\n",
            "   Train Loss: 1.3688\n",
            "   Val Loss:   3.0028\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0028)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 12/15 - Training...\n",
            "   Batch 0/907, Loss: 1.1016\n",
            "   Batch 50/907, Loss: 1.1936\n",
            "   Batch 100/907, Loss: 1.3854\n",
            "   Batch 150/907, Loss: 1.2740\n",
            "   Batch 200/907, Loss: 0.9629\n",
            "   Batch 250/907, Loss: 1.8304\n",
            "   Batch 300/907, Loss: 1.1359\n",
            "   Batch 350/907, Loss: 1.2587\n",
            "   Batch 400/907, Loss: 1.1150\n",
            "   Batch 450/907, Loss: 0.9765\n",
            "   Batch 500/907, Loss: 1.2528\n",
            "   Batch 550/907, Loss: 0.9542\n",
            "   Batch 600/907, Loss: 1.3638\n",
            "   Batch 650/907, Loss: 1.1793\n",
            "   Batch 700/907, Loss: 1.3407\n",
            "   Batch 750/907, Loss: 1.1985\n",
            "   Batch 800/907, Loss: 1.4628\n",
            "   Batch 850/907, Loss: 1.9484\n",
            "   Batch 900/907, Loss: 1.2602\n",
            "Epoch 12/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 12 Summary:\n",
            "   Train Loss: 1.2783\n",
            "   Val Loss:   3.0453\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 13/15 - Training...\n",
            "   Batch 0/907, Loss: 1.1440\n",
            "   Batch 50/907, Loss: 1.7394\n",
            "   Batch 100/907, Loss: 1.2466\n",
            "   Batch 150/907, Loss: 1.4213\n",
            "   Batch 200/907, Loss: 1.1448\n",
            "   Batch 250/907, Loss: 0.9530\n",
            "   Batch 300/907, Loss: 1.0495\n",
            "   Batch 350/907, Loss: 1.2685\n",
            "   Batch 400/907, Loss: 0.9321\n",
            "   Batch 450/907, Loss: 1.1962\n",
            "   Batch 500/907, Loss: 1.2868\n",
            "   Batch 550/907, Loss: 1.3654\n",
            "   Batch 600/907, Loss: 0.9817\n",
            "   Batch 650/907, Loss: 0.8725\n",
            "   Batch 700/907, Loss: 1.3520\n",
            "   Batch 750/907, Loss: 1.3843\n",
            "   Batch 800/907, Loss: 1.5602\n",
            "   Batch 850/907, Loss: 1.1724\n",
            "   Batch 900/907, Loss: 1.2437\n",
            "Epoch 13/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 13 Summary:\n",
            "   Train Loss: 1.2054\n",
            "   Val Loss:   2.9856\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 2.9856)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 14/15 - Training...\n",
            "   Batch 0/907, Loss: 1.2461\n",
            "   Batch 50/907, Loss: 1.3240\n",
            "   Batch 100/907, Loss: 0.9865\n",
            "   Batch 150/907, Loss: 1.2861\n",
            "   Batch 200/907, Loss: 1.0276\n",
            "   Batch 250/907, Loss: 1.0274\n",
            "   Batch 300/907, Loss: 1.1856\n",
            "   Batch 350/907, Loss: 1.1592\n",
            "   Batch 400/907, Loss: 0.9563\n",
            "   Batch 450/907, Loss: 1.2085\n",
            "   Batch 500/907, Loss: 1.7127\n",
            "   Batch 550/907, Loss: 1.0666\n",
            "   Batch 600/907, Loss: 0.9846\n",
            "   Batch 650/907, Loss: 1.3392\n",
            "   Batch 700/907, Loss: 1.4689\n",
            "   Batch 750/907, Loss: 1.2528\n",
            "   Batch 800/907, Loss: 1.2976\n",
            "   Batch 850/907, Loss: 1.3667\n",
            "   Batch 900/907, Loss: 0.8643\n",
            "Epoch 14/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 14 Summary:\n",
            "   Train Loss: 1.1246\n",
            "   Val Loss:   2.9977\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 15/15 - Training...\n",
            "   Batch 0/907, Loss: 1.4106\n",
            "   Batch 50/907, Loss: 0.8015\n",
            "   Batch 100/907, Loss: 1.0736\n",
            "   Batch 150/907, Loss: 0.9904\n",
            "   Batch 200/907, Loss: 1.0944\n",
            "   Batch 250/907, Loss: 1.1332\n",
            "   Batch 300/907, Loss: 1.4340\n",
            "   Batch 350/907, Loss: 0.8390\n",
            "   Batch 400/907, Loss: 0.9092\n",
            "   Batch 450/907, Loss: 1.4927\n",
            "   Batch 500/907, Loss: 0.8684\n",
            "   Batch 550/907, Loss: 1.1161\n",
            "   Batch 600/907, Loss: 0.7893\n",
            "   Batch 650/907, Loss: 1.2090\n",
            "   Batch 700/907, Loss: 1.0454\n",
            "   Batch 750/907, Loss: 1.1931\n",
            "   Batch 800/907, Loss: 1.0342\n",
            "   Batch 850/907, Loss: 1.2331\n",
            "   Batch 900/907, Loss: 1.1634\n",
            "Epoch 15/15 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 15 Summary:\n",
            "   Train Loss: 1.0646\n",
            "   Val Loss:   3.0020\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (2/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            " Training completed!\n",
            "Best validation loss: 2.9856\n",
            "Total epochs trained: 15\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 15 # Số epoch\n",
        "CLIP = 1\n",
        "\n",
        "train_losses, val_losses = train(model, train_iterator, valid_iterator,\n",
        "                                 criterion, optimizer,\n",
        "                                 N_EPOCHS, device, clip=CLIP,\n",
        "                                 teacher_forcing_ratio=0.5,\n",
        "                                 patience=3, model_path='best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2y2v9V2JOrxF",
      "metadata": {
        "id": "2y2v9V2JOrxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "e1676c1a-ccb5-4501-84cc-23b50f79237b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Vẽ biểu đồ Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Biểu đồ huấn luyện Model LSTM')\n",
        "plt.savefig('loss_chart.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_5at0VL9Osow",
      "metadata": {
        "id": "_5at0VL9Osow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc2f6a8-a380-4f5e-cc6c-e1f03552eec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải lại tập Test để lấy ví dụ...\n",
            "--> Đã tải xong test_dataset với 1000 câu.\n",
            "Src: A mother and her young song enjoying a beautiful day outside.\n",
            "Trg: Une mère et son jeune fils profitant d'une belle journée dehors.\n",
            "Pred: une mère mère et sa jeune jeune jeune profitant d' une belle journée .\n"
          ]
        }
      ],
      "source": [
        "from src.dataset import TranslationDataset, build_vocab_and_tokenizers\n",
        "\n",
        "# 1. Lấy lại bộ từ điển và tokenizer\n",
        "# src_vocab, trg_vocab = build_vocab_and_tokenizers()\n",
        "\n",
        "# 2. Khởi tạo lại biến test_dataset thủ công\n",
        "print(\"Đang tải lại tập Test để lấy ví dụ...\")\n",
        "test_dataset = TranslationDataset(\n",
        "    'data/raw/test_2016_flickr.en',\n",
        "    'data/raw/test_2016_flickr.fr',\n",
        "    src_vocab, trg_vocab, src_tokenizer, trg_tokenizer\n",
        ")\n",
        "\n",
        "print(f\"--> Đã tải xong test_dataset với {len(test_dataset)} câu.\")\n",
        "# Load model tốt nhất\n",
        "checkpoint = torch.load('best_model.pth', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "\n",
        "def translate_sentence(sentence, src_tokenizer, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Tokenize\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = src_tokenizer(sentence)\n",
        "    else:\n",
        "        tokens = sentence\n",
        "\n",
        "    # 2. Convert to index\n",
        "    src_indexes = [src_vocab['<sos>']] + [src_vocab[t] for t in tokens] + [src_vocab['<eos>']]\n",
        "\n",
        "    # 3. Tensor hóa\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    src_len = torch.tensor([len(src_indexes)], dtype=torch.long).to(device)\n",
        "\n",
        "    # 4. Encode\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden, encoder_cell = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    # decoder hidden/cell init\n",
        "    hidden = encoder_hidden\n",
        "    cell = encoder_cell\n",
        "\n",
        "    # 5. Bắt đầu decode\n",
        "    trg_indexes = [trg_vocab['<sos>']]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).unsqueeze(0).to(device)  # [1,1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell, _ = model.decoder(\n",
        "                trg_tensor,      # [1,1]\n",
        "                hidden,          # hidden state\n",
        "                cell,            # cell state\n",
        "                encoder_outputs   # context cố định từ encoder\n",
        "            )\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.lookup_token(i) for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1]   # bỏ <sos> và <eos>\n",
        "\n",
        "\n",
        "# Thử dịch 1 câu trong tập test\n",
        "# --- SỬA LẠI ĐOẠN LẤY VÍ DỤ ---\n",
        "\n",
        "# 1. Chọn index\n",
        "example_idx = 10\n",
        "\n",
        "# 2. Lấy trực tiếp từ list chứa text thô (Raw text)\n",
        "src = test_dataset.src_data[example_idx].strip()\n",
        "trg = test_dataset.trg_data[example_idx].strip()\n",
        "\n",
        "print(f'Src: {src}')\n",
        "print(f'Trg: {trg}')\n",
        "\n",
        "# 3. Dịch\n",
        "translation = translate_sentence(src, src_tokenizer, model, device)\n",
        "\n",
        "print(f'Pred: {\" \".join(translation)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MBSaCTD9OwR6",
      "metadata": {
        "id": "MBSaCTD9OwR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c5b048-b7c0-4b46-c3f1-fef53c5ced62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tính toán BLEU trên 1000 câu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|██████████| 1000/1000 [00:15<00:00, 64.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BLEU score = 35.21\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_bleu(data, model, device, max_len=50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    # Chuyển model sang chế độ đánh giá\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Đang tính toán BLEU trên {len(data)} câu...\")\n",
        "    for i in tqdm(range(len(data)), desc=\"Translating\"):\n",
        "\n",
        "        # 1. Lấy câu gốc và câu đích dạng chuỗi\n",
        "        src_raw = data.src_data[i].strip()\n",
        "        trg_raw = data.trg_data[i].strip()\n",
        "\n",
        "        # 2. Model dịch và trả về list token\n",
        "        pred_trg = translate_sentence(src_raw, src_tokenizer, model, device, max_len)\n",
        "\n",
        "        # 3. Tokenize câu đích (Ground Truth)\n",
        "        if isinstance(trg_raw, str):\n",
        "            trg_tokenized = trg_tokenizer(trg_raw)\n",
        "        else:\n",
        "            trg_tokenized = list(trg_raw)\n",
        "\n",
        "        # --- Làm sạch (Filter) ---\n",
        "        ignore_tokens = [\"<sos>\", \"<eos>\", \"<pad>\", \"<unk>\"]\n",
        "\n",
        "        pred_trg_clean = [tok for tok in pred_trg if tok not in ignore_tokens]\n",
        "        trg_tokenized_clean = [tok for tok in trg_tokenized if tok not in ignore_tokens]\n",
        "\n",
        "        # 4. Thêm vào list theo đúng format torchtext yêu cầu\n",
        "        pred_trgs.append(pred_trg_clean)\n",
        "        trgs.append([trg_tokenized_clean])\n",
        "\n",
        "    # --- Tính BLEU ---\n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "score = calculate_bleu(test_dataset, model, device)\n",
        "print(f\"\\nBLEU score = {score*100:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}