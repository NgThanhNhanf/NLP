{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "JKtnQ7Y1_J30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JKtnQ7Y1_J30",
        "outputId": "9c5001fc-c083-445f-c342-f9ad99f20731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.12/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.3.1 torchtext==0.18.0 portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "AdByqGW3ZAXZ",
      "metadata": {
        "collapsed": true,
        "id": "AdByqGW3ZAXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1a0504-757f-47b9-d07b-2031dd35052d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'NLP' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone  https://github.com/NgThanhNhanf/NLP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "739bf4d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "739bf4d4",
        "outputId": "6e3258a5-936a-49a8-d091-6ab72fb1f375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b59a600a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b59a600a",
        "outputId": "51486f1a-747b-4431-be9c-56f7804caf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05afd97",
      "metadata": {
        "id": "e05afd97"
      },
      "source": [
        "After downloading, you can re-run the initialization cell (`b2bf295b`) to confirm that Spacy loads the models correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "mJo_QEZ3eFc-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJo_QEZ3eFc-",
        "outputId": "3645f3c2-e3b3-4cae-e022-d10ca8d32adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP\n"
          ]
        }
      ],
      "source": [
        "%cd /content/NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "beKp8unreKcq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "beKp8unreKcq",
        "outputId": "1c89bc3b-b1e9-458b-d2af-5cb0bcf32549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.3.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.8.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (2.12.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (5.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext->-r requirements.txt (line 2)) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.8.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (4.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.14)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 3)) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "37P1IFku9Uew",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37P1IFku9Uew",
        "outputId": "37884395-a1c6-42e2-81eb-3290d6421c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thiết bị đang sử dụng: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from src.model_base import Encoder, Decoder, Seq2Seq\n",
        "from src.model_attention import EncoderAttention, DecoderAttention, Seq2SeqAttention\n",
        "from src.dataset import get_data_loaders, build_vocab_and_tokenizers\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Kiểm tra GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Thiết bị đang sử dụng: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "PIP0WfvnNYrC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIP0WfvnNYrC",
        "outputId": "7ad9d785-0624-402a-caca-fa7c75b7ea3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang xử lý dữ liệu...\n",
            "Đang xây dựng từ điển (Vocabulary)...\n",
            "Đang tạo Dataset...\n",
            "Đang tạo DataLoader...\n",
            "Số lượng câu Train: 29024\n",
            "Kích thước từ điển Anh: 5893\n",
            "Kích thước từ điển Pháp: 6471\n"
          ]
        }
      ],
      "source": [
        "print(\"Đang xử lý dữ liệu...\")\n",
        "\n",
        "# 1. Đường dẫn file (Đảm bảo bạn đã đổi tên file thành test.en, test.fr như mình dặn)\n",
        "SRC_FILE = 'data/raw/train.en'\n",
        "TRG_FILE = 'data/raw/train.fr'\n",
        "\n",
        "# 2. Xây dựng Vocab & Tokenizer\n",
        "src_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "trg_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "\n",
        "src_vocab, trg_vocab = build_vocab_and_tokenizers(src_tokenizer, trg_tokenizer)\n",
        "\n",
        "# 3. Tạo Iterators (DataLoaders)\n",
        "BATCH_SIZE = 32\n",
        "train_iterator, valid_iterator, test_iterator = get_data_loaders(batch_size=BATCH_SIZE, en_tokenizer = src_tokenizer, fr_tokenizer = trg_tokenizer,\n",
        "                                                                 src_vocab = src_vocab,  trg_vocab = trg_vocab)\n",
        "\n",
        "print(f\"Số lượng câu Train: {len(train_iterator) * BATCH_SIZE}\")\n",
        "print(f\"Kích thước từ điển Anh: {len(src_vocab)}\")\n",
        "print(f\"Kích thước từ điển Pháp: {len(trg_vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem bên trong từ điển\n",
        "src_vocab.get_itos()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCsEwi2WN4V5",
        "outputId": "d36726d0-8897-438d-e182-de0f1956a96d"
      },
      "id": "kCsEwi2WN4V5",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<sos>', '<eos>', 'a', '.', 'in', 'the', 'on', 'man']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "v9_gXicKOdIi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9_gXicKOdIi",
        "outputId": "2c596bee-eda2-4d97-8e8e-68720b8d56ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mô hình có 22,941,511 tham số có thể huấn luyện\n"
          ]
        }
      ],
      "source": [
        "# --- HYPERPARAMETERS ---\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(trg_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# --- KHỞI TẠO ---\n",
        "enc = EncoderAttention(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = DecoderAttention(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2SeqAttention(enc, dec, device).to(device)\n",
        "\n",
        "# --- KHỞI TẠO TRỌNG SỐ (WEIGHTS) ---\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Mô hình có {count_parameters(model):,} tham số có thể huấn luyện')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8bkmb9HQOjGT",
      "metadata": {
        "id": "8bkmb9HQOjGT"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# Bỏ qua padding token khi tính loss\n",
        "TRG_PAD_IDX = trg_vocab['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3lg93jLsOm_L",
      "metadata": {
        "id": "3lg93jLsOm_L"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer,\n",
        "                        num_epochs, device, clip=1.0, teacher_forcing_ratio=0.5,\n",
        "                        patience=3, model_path='best_model.pth'):\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"Bắt đầu training với {num_epochs} epochs\")\n",
        "    print(f\"Teacher forcing ratio: {teacher_forcing_ratio}\")\n",
        "    print(f\"Gradient clip: {clip}\")\n",
        "    print(f\"Early stopping patience: {patience}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # === TRAINING PHASE ===\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Progress bar\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs} - Training...\")\n",
        "\n",
        "        for batch_idx, (source, target, source_lengths) in enumerate(train_loader):\n",
        "            source, target = source.to(device), target.to(device)\n",
        "            source_lengths = source_lengths.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward với teacher forcing\n",
        "            output = model(source, target, source_lengths, teacher_forcing_ratio)\n",
        "\n",
        "            # Tính loss\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            target = target[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping với tham số\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "            # In progress mỗi 50 batch\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"   Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / batch_count\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # === VALIDATION PHASE ===\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Validating...\")\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        batch_count_val = 0\n",
        "\n",
        "        # Lấy một batch từ DataLoader\n",
        "        batch = next(iter(val_loader))\n",
        "\n",
        "        print(f\"Số phần tử trong batch: {len(batch)}\")\n",
        "        print(f\"Kiểu dữ liệu batch: {type(batch)}\")\n",
        "\n",
        "        # Kiểm tra từng phần tử\n",
        "        for i, item in enumerate(batch):\n",
        "            print(f\"  Phần tử {i}: type={type(item)}, shape={item.shape if hasattr(item, 'shape') else len(item)}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for source, target, source_lengths in val_loader:\n",
        "                source, target = source.to(device), target.to(device)\n",
        "\n",
        "                # Evaluation: teacher forcing = 0\n",
        "                output = model(source, target, source_lengths, teacher_forcing_ratio=0)\n",
        "\n",
        "                output_dim = output.shape[-1]\n",
        "                output = output[:, 1:].reshape(-1, output_dim)\n",
        "                target = target[:, 1:].reshape(-1)\n",
        "\n",
        "                loss = criterion(output, target)\n",
        "                epoch_val_loss += loss.item()\n",
        "                batch_count_val += 1\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / batch_count_val\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # === IN KẾT QUẢ ===\n",
        "        print(f\"\\n Epoch {epoch+1} Summary:\")\n",
        "        print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
        "        print(f\"   Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # === EARLY STOPPING & SAVE BEST MODEL ===\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "            }, model_path)\n",
        "            print(f\"   Best model saved! (Loss: {avg_val_loss:.4f})\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"   No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs!\")\n",
        "                print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    print(f\"\\n Training completed!\")\n",
        "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "    print(f\"Total epochs trained: {len(train_losses)}\")\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "M8WLff0_OoI7",
      "metadata": {
        "id": "M8WLff0_OoI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b09b3f-b4bb-4848-9d3c-d602eafe4961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu training với 20 epochs\n",
            "Teacher forcing ratio: 0.5\n",
            "Gradient clip: 1\n",
            "Early stopping patience: 3\n",
            "============================================================\n",
            "\n",
            "Epoch 1/20 - Training...\n",
            "   Batch 0/907, Loss: 8.7694\n",
            "   Batch 50/907, Loss: 5.1366\n",
            "   Batch 100/907, Loss: 5.0474\n",
            "   Batch 150/907, Loss: 4.9315\n",
            "   Batch 200/907, Loss: 5.0107\n",
            "   Batch 250/907, Loss: 4.8588\n",
            "   Batch 300/907, Loss: 4.8253\n",
            "   Batch 350/907, Loss: 4.4770\n",
            "   Batch 400/907, Loss: 4.7903\n",
            "   Batch 450/907, Loss: 4.3437\n",
            "   Batch 500/907, Loss: 4.6882\n",
            "   Batch 550/907, Loss: 4.3040\n",
            "   Batch 600/907, Loss: 4.0818\n",
            "   Batch 650/907, Loss: 4.4471\n",
            "   Batch 700/907, Loss: 4.1738\n",
            "   Batch 750/907, Loss: 4.2970\n",
            "   Batch 800/907, Loss: 4.2492\n",
            "   Batch 850/907, Loss: 3.8337\n",
            "   Batch 900/907, Loss: 4.0845\n",
            "Epoch 1/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 1 Summary:\n",
            "   Train Loss: 4.6343\n",
            "   Val Loss:   4.4651\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 4.4651)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 2/20 - Training...\n",
            "   Batch 0/907, Loss: 4.2143\n",
            "   Batch 50/907, Loss: 3.9876\n",
            "   Batch 100/907, Loss: 3.7895\n",
            "   Batch 150/907, Loss: 4.3324\n",
            "   Batch 200/907, Loss: 3.9571\n",
            "   Batch 250/907, Loss: 3.8649\n",
            "   Batch 300/907, Loss: 3.9802\n",
            "   Batch 350/907, Loss: 3.4360\n",
            "   Batch 400/907, Loss: 3.7600\n",
            "   Batch 450/907, Loss: 3.5443\n",
            "   Batch 500/907, Loss: 3.4613\n",
            "   Batch 550/907, Loss: 3.7046\n",
            "   Batch 600/907, Loss: 3.4437\n",
            "   Batch 650/907, Loss: 3.2256\n",
            "   Batch 700/907, Loss: 3.5627\n",
            "   Batch 750/907, Loss: 3.1707\n",
            "   Batch 800/907, Loss: 3.3165\n",
            "   Batch 850/907, Loss: 3.5772\n",
            "   Batch 900/907, Loss: 3.2830\n",
            "Epoch 2/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 2 Summary:\n",
            "   Train Loss: 3.6919\n",
            "   Val Loss:   3.8764\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.8764)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 3/20 - Training...\n",
            "   Batch 0/907, Loss: 3.0312\n",
            "   Batch 50/907, Loss: 3.1735\n",
            "   Batch 100/907, Loss: 3.1449\n",
            "   Batch 150/907, Loss: 3.1494\n",
            "   Batch 200/907, Loss: 3.0892\n",
            "   Batch 250/907, Loss: 2.9958\n",
            "   Batch 300/907, Loss: 3.1416\n",
            "   Batch 350/907, Loss: 2.5672\n",
            "   Batch 400/907, Loss: 2.6772\n",
            "   Batch 450/907, Loss: 2.8708\n",
            "   Batch 500/907, Loss: 3.0988\n",
            "   Batch 550/907, Loss: 2.7805\n",
            "   Batch 600/907, Loss: 2.7505\n",
            "   Batch 650/907, Loss: 2.9147\n",
            "   Batch 700/907, Loss: 2.8258\n",
            "   Batch 750/907, Loss: 3.1254\n",
            "   Batch 800/907, Loss: 2.5403\n",
            "   Batch 850/907, Loss: 3.0029\n",
            "   Batch 900/907, Loss: 3.4692\n",
            "Epoch 3/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 3 Summary:\n",
            "   Train Loss: 2.9879\n",
            "   Val Loss:   3.4445\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.4445)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 4/20 - Training...\n",
            "   Batch 0/907, Loss: 2.4317\n",
            "   Batch 50/907, Loss: 1.8670\n",
            "   Batch 100/907, Loss: 3.1766\n",
            "   Batch 150/907, Loss: 2.5144\n",
            "   Batch 200/907, Loss: 2.8211\n",
            "   Batch 250/907, Loss: 2.4465\n",
            "   Batch 300/907, Loss: 2.2778\n",
            "   Batch 350/907, Loss: 2.4804\n",
            "   Batch 400/907, Loss: 2.3236\n",
            "   Batch 450/907, Loss: 2.7687\n",
            "   Batch 500/907, Loss: 2.6416\n",
            "   Batch 550/907, Loss: 2.6171\n",
            "   Batch 600/907, Loss: 2.7235\n",
            "   Batch 650/907, Loss: 2.5202\n",
            "   Batch 700/907, Loss: 2.2834\n",
            "   Batch 750/907, Loss: 2.5073\n",
            "   Batch 800/907, Loss: 2.4257\n",
            "   Batch 850/907, Loss: 2.8898\n",
            "   Batch 900/907, Loss: 2.4336\n",
            "Epoch 4/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 4 Summary:\n",
            "   Train Loss: 2.5612\n",
            "   Val Loss:   3.2595\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.2595)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 5/20 - Training...\n",
            "   Batch 0/907, Loss: 2.3439\n",
            "   Batch 50/907, Loss: 2.5987\n",
            "   Batch 100/907, Loss: 2.2165\n",
            "   Batch 150/907, Loss: 2.5690\n",
            "   Batch 200/907, Loss: 2.1174\n",
            "   Batch 250/907, Loss: 2.5371\n",
            "   Batch 300/907, Loss: 2.3254\n",
            "   Batch 350/907, Loss: 2.2831\n",
            "   Batch 400/907, Loss: 2.1288\n",
            "   Batch 450/907, Loss: 2.6579\n",
            "   Batch 500/907, Loss: 2.0861\n",
            "   Batch 550/907, Loss: 2.0939\n",
            "   Batch 600/907, Loss: 2.1841\n",
            "   Batch 650/907, Loss: 2.2119\n",
            "   Batch 700/907, Loss: 2.0035\n",
            "   Batch 750/907, Loss: 2.4755\n",
            "   Batch 800/907, Loss: 1.8035\n",
            "   Batch 850/907, Loss: 2.3306\n",
            "   Batch 900/907, Loss: 1.8529\n",
            "Epoch 5/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 5 Summary:\n",
            "   Train Loss: 2.2642\n",
            "   Val Loss:   3.1266\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.1266)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 6/20 - Training...\n",
            "   Batch 0/907, Loss: 1.9396\n",
            "   Batch 50/907, Loss: 1.8882\n",
            "   Batch 100/907, Loss: 1.8980\n",
            "   Batch 150/907, Loss: 2.1882\n",
            "   Batch 200/907, Loss: 1.8421\n",
            "   Batch 250/907, Loss: 2.3046\n",
            "   Batch 300/907, Loss: 2.0038\n",
            "   Batch 350/907, Loss: 2.3192\n",
            "   Batch 400/907, Loss: 1.8889\n",
            "   Batch 450/907, Loss: 1.9972\n",
            "   Batch 500/907, Loss: 2.1996\n",
            "   Batch 550/907, Loss: 1.9150\n",
            "   Batch 600/907, Loss: 2.2910\n",
            "   Batch 650/907, Loss: 2.0242\n",
            "   Batch 700/907, Loss: 2.0920\n",
            "   Batch 750/907, Loss: 1.8435\n",
            "   Batch 800/907, Loss: 1.6201\n",
            "   Batch 850/907, Loss: 2.1943\n",
            "   Batch 900/907, Loss: 1.8855\n",
            "Epoch 6/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 6 Summary:\n",
            "   Train Loss: 2.0360\n",
            "   Val Loss:   3.0624\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0624)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 7/20 - Training...\n",
            "   Batch 0/907, Loss: 1.8350\n",
            "   Batch 50/907, Loss: 1.8977\n",
            "   Batch 100/907, Loss: 1.6818\n",
            "   Batch 150/907, Loss: 1.4921\n",
            "   Batch 200/907, Loss: 2.0872\n",
            "   Batch 250/907, Loss: 1.7615\n",
            "   Batch 300/907, Loss: 2.2586\n",
            "   Batch 350/907, Loss: 1.6856\n",
            "   Batch 400/907, Loss: 1.9147\n",
            "   Batch 450/907, Loss: 1.9337\n",
            "   Batch 500/907, Loss: 1.8860\n",
            "   Batch 550/907, Loss: 2.0330\n",
            "   Batch 600/907, Loss: 1.8536\n",
            "   Batch 650/907, Loss: 2.1664\n",
            "   Batch 700/907, Loss: 2.1076\n",
            "   Batch 750/907, Loss: 1.7419\n",
            "   Batch 800/907, Loss: 1.7504\n",
            "   Batch 850/907, Loss: 1.9535\n",
            "   Batch 900/907, Loss: 1.6237\n",
            "Epoch 7/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 7 Summary:\n",
            "   Train Loss: 1.8698\n",
            "   Val Loss:   3.0581\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0581)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 8/20 - Training...\n",
            "   Batch 0/907, Loss: 1.7865\n",
            "   Batch 50/907, Loss: 1.6491\n",
            "   Batch 100/907, Loss: 1.9286\n",
            "   Batch 150/907, Loss: 1.7504\n",
            "   Batch 200/907, Loss: 1.6620\n",
            "   Batch 250/907, Loss: 1.4713\n",
            "   Batch 300/907, Loss: 1.8336\n",
            "   Batch 350/907, Loss: 2.2059\n",
            "   Batch 400/907, Loss: 1.6135\n",
            "   Batch 450/907, Loss: 1.1447\n",
            "   Batch 500/907, Loss: 1.5838\n",
            "   Batch 550/907, Loss: 1.5725\n",
            "   Batch 600/907, Loss: 1.5978\n",
            "   Batch 650/907, Loss: 1.8129\n",
            "   Batch 700/907, Loss: 1.7718\n",
            "   Batch 750/907, Loss: 1.5277\n",
            "   Batch 800/907, Loss: 1.4868\n",
            "   Batch 850/907, Loss: 1.6903\n",
            "   Batch 900/907, Loss: 1.5934\n",
            "Epoch 8/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 8 Summary:\n",
            "   Train Loss: 1.7269\n",
            "   Val Loss:   3.0465\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0465)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 9/20 - Training...\n",
            "   Batch 0/907, Loss: 1.7229\n",
            "   Batch 50/907, Loss: 1.1570\n",
            "   Batch 100/907, Loss: 1.3194\n",
            "   Batch 150/907, Loss: 1.5665\n",
            "   Batch 200/907, Loss: 1.5475\n",
            "   Batch 250/907, Loss: 1.6328\n",
            "   Batch 300/907, Loss: 1.4216\n",
            "   Batch 350/907, Loss: 1.7931\n",
            "   Batch 400/907, Loss: 1.5724\n",
            "   Batch 450/907, Loss: 1.4918\n",
            "   Batch 500/907, Loss: 1.7452\n",
            "   Batch 550/907, Loss: 1.7650\n",
            "   Batch 600/907, Loss: 1.8250\n",
            "   Batch 650/907, Loss: 1.8414\n",
            "   Batch 700/907, Loss: 1.2837\n",
            "   Batch 750/907, Loss: 1.3787\n",
            "   Batch 800/907, Loss: 1.7836\n",
            "   Batch 850/907, Loss: 1.4676\n",
            "   Batch 900/907, Loss: 2.2406\n",
            "Epoch 9/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 9 Summary:\n",
            "   Train Loss: 1.5916\n",
            "   Val Loss:   3.0078\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0078)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 10/20 - Training...\n",
            "   Batch 0/907, Loss: 1.2332\n",
            "   Batch 50/907, Loss: 1.5194\n",
            "   Batch 100/907, Loss: 1.3976\n",
            "   Batch 150/907, Loss: 1.7641\n",
            "   Batch 200/907, Loss: 2.0566\n",
            "   Batch 250/907, Loss: 1.3821\n",
            "   Batch 300/907, Loss: 1.5776\n",
            "   Batch 350/907, Loss: 1.4682\n",
            "   Batch 400/907, Loss: 1.2699\n",
            "   Batch 450/907, Loss: 1.3959\n",
            "   Batch 500/907, Loss: 1.2963\n",
            "   Batch 550/907, Loss: 1.2680\n",
            "   Batch 600/907, Loss: 1.7015\n",
            "   Batch 650/907, Loss: 1.8726\n",
            "   Batch 700/907, Loss: 1.2101\n",
            "   Batch 750/907, Loss: 1.7194\n",
            "   Batch 800/907, Loss: 1.1712\n",
            "   Batch 850/907, Loss: 1.1924\n",
            "   Batch 900/907, Loss: 1.3789\n",
            "Epoch 10/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 10 Summary:\n",
            "   Train Loss: 1.4724\n",
            "   Val Loss:   3.0186\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 11/20 - Training...\n",
            "   Batch 0/907, Loss: 1.8154\n",
            "   Batch 50/907, Loss: 1.5835\n",
            "   Batch 100/907, Loss: 1.4032\n",
            "   Batch 150/907, Loss: 1.2356\n",
            "   Batch 200/907, Loss: 1.2981\n",
            "   Batch 250/907, Loss: 1.0523\n",
            "   Batch 300/907, Loss: 1.3015\n",
            "   Batch 350/907, Loss: 1.1704\n",
            "   Batch 400/907, Loss: 1.4452\n",
            "   Batch 450/907, Loss: 1.3428\n",
            "   Batch 500/907, Loss: 1.4398\n",
            "   Batch 550/907, Loss: 1.4392\n",
            "   Batch 600/907, Loss: 1.5525\n",
            "   Batch 650/907, Loss: 1.2851\n",
            "   Batch 700/907, Loss: 1.2940\n",
            "   Batch 750/907, Loss: 1.3929\n",
            "   Batch 800/907, Loss: 1.7412\n",
            "   Batch 850/907, Loss: 1.4694\n",
            "   Batch 900/907, Loss: 2.2452\n",
            "Epoch 11/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 11 Summary:\n",
            "   Train Loss: 1.3688\n",
            "   Val Loss:   3.0028\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 3.0028)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 12/20 - Training...\n",
            "   Batch 0/907, Loss: 1.1016\n",
            "   Batch 50/907, Loss: 1.1936\n",
            "   Batch 100/907, Loss: 1.3854\n",
            "   Batch 150/907, Loss: 1.2740\n",
            "   Batch 200/907, Loss: 0.9629\n",
            "   Batch 250/907, Loss: 1.8304\n",
            "   Batch 300/907, Loss: 1.1359\n",
            "   Batch 350/907, Loss: 1.2587\n",
            "   Batch 400/907, Loss: 1.1150\n",
            "   Batch 450/907, Loss: 0.9765\n",
            "   Batch 500/907, Loss: 1.2528\n",
            "   Batch 550/907, Loss: 0.9542\n",
            "   Batch 600/907, Loss: 1.3638\n",
            "   Batch 650/907, Loss: 1.1793\n",
            "   Batch 700/907, Loss: 1.3407\n",
            "   Batch 750/907, Loss: 1.1985\n",
            "   Batch 800/907, Loss: 1.4628\n",
            "   Batch 850/907, Loss: 1.9484\n",
            "   Batch 900/907, Loss: 1.2602\n",
            "Epoch 12/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 12 Summary:\n",
            "   Train Loss: 1.2783\n",
            "   Val Loss:   3.0453\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 13/20 - Training...\n",
            "   Batch 0/907, Loss: 1.1440\n",
            "   Batch 50/907, Loss: 1.7394\n",
            "   Batch 100/907, Loss: 1.2466\n",
            "   Batch 150/907, Loss: 1.4213\n",
            "   Batch 200/907, Loss: 1.1448\n",
            "   Batch 250/907, Loss: 0.9530\n",
            "   Batch 300/907, Loss: 1.0495\n",
            "   Batch 350/907, Loss: 1.2685\n",
            "   Batch 400/907, Loss: 0.9321\n",
            "   Batch 450/907, Loss: 1.1962\n",
            "   Batch 500/907, Loss: 1.2868\n",
            "   Batch 550/907, Loss: 1.3654\n",
            "   Batch 600/907, Loss: 0.9817\n",
            "   Batch 650/907, Loss: 0.8725\n",
            "   Batch 700/907, Loss: 1.3520\n",
            "   Batch 750/907, Loss: 1.3843\n",
            "   Batch 800/907, Loss: 1.5602\n",
            "   Batch 850/907, Loss: 1.1724\n",
            "   Batch 900/907, Loss: 1.2437\n",
            "Epoch 13/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 13 Summary:\n",
            "   Train Loss: 1.2054\n",
            "   Val Loss:   2.9856\n",
            "   Learning Rate: 0.000300\n",
            "   Best model saved! (Loss: 2.9856)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 14/20 - Training...\n",
            "   Batch 0/907, Loss: 1.2461\n",
            "   Batch 50/907, Loss: 1.3240\n",
            "   Batch 100/907, Loss: 0.9865\n",
            "   Batch 150/907, Loss: 1.2861\n",
            "   Batch 200/907, Loss: 1.0276\n",
            "   Batch 250/907, Loss: 1.0274\n",
            "   Batch 300/907, Loss: 1.1856\n",
            "   Batch 350/907, Loss: 1.1592\n",
            "   Batch 400/907, Loss: 0.9563\n",
            "   Batch 450/907, Loss: 1.2085\n",
            "   Batch 500/907, Loss: 1.7127\n",
            "   Batch 550/907, Loss: 1.0666\n",
            "   Batch 600/907, Loss: 0.9846\n",
            "   Batch 650/907, Loss: 1.3392\n",
            "   Batch 700/907, Loss: 1.4689\n",
            "   Batch 750/907, Loss: 1.2528\n",
            "   Batch 800/907, Loss: 1.2976\n",
            "   Batch 850/907, Loss: 1.3667\n",
            "   Batch 900/907, Loss: 0.8643\n",
            "Epoch 14/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 14 Summary:\n",
            "   Train Loss: 1.1246\n",
            "   Val Loss:   2.9977\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (1/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 15/20 - Training...\n",
            "   Batch 0/907, Loss: 1.4106\n",
            "   Batch 50/907, Loss: 0.8015\n",
            "   Batch 100/907, Loss: 1.0736\n",
            "   Batch 150/907, Loss: 0.9904\n",
            "   Batch 200/907, Loss: 1.0944\n",
            "   Batch 250/907, Loss: 1.1332\n",
            "   Batch 300/907, Loss: 1.4340\n",
            "   Batch 350/907, Loss: 0.8390\n",
            "   Batch 400/907, Loss: 0.9092\n",
            "   Batch 450/907, Loss: 1.4927\n",
            "   Batch 500/907, Loss: 0.8684\n",
            "   Batch 550/907, Loss: 1.1161\n",
            "   Batch 600/907, Loss: 0.7893\n",
            "   Batch 650/907, Loss: 1.2090\n",
            "   Batch 700/907, Loss: 1.0454\n",
            "   Batch 750/907, Loss: 1.1931\n",
            "   Batch 800/907, Loss: 1.0342\n",
            "   Batch 850/907, Loss: 1.2331\n",
            "   Batch 900/907, Loss: 1.1634\n",
            "Epoch 15/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 15 Summary:\n",
            "   Train Loss: 1.0646\n",
            "   Val Loss:   3.0020\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (2/3)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 16/20 - Training...\n",
            "   Batch 0/907, Loss: 1.1107\n",
            "   Batch 50/907, Loss: 1.0327\n",
            "   Batch 100/907, Loss: 0.8934\n",
            "   Batch 150/907, Loss: 1.3260\n",
            "   Batch 200/907, Loss: 1.2020\n",
            "   Batch 250/907, Loss: 0.7714\n",
            "   Batch 300/907, Loss: 0.9053\n",
            "   Batch 350/907, Loss: 0.7413\n",
            "   Batch 400/907, Loss: 0.7647\n",
            "   Batch 450/907, Loss: 0.6776\n",
            "   Batch 500/907, Loss: 0.7367\n",
            "   Batch 550/907, Loss: 0.8770\n",
            "   Batch 600/907, Loss: 1.0372\n",
            "   Batch 650/907, Loss: 1.0444\n",
            "   Batch 700/907, Loss: 1.2857\n",
            "   Batch 750/907, Loss: 1.4257\n",
            "   Batch 800/907, Loss: 0.9624\n",
            "   Batch 850/907, Loss: 1.0414\n",
            "   Batch 900/907, Loss: 0.9395\n",
            "Epoch 16/20 - Validating...\n",
            "Số phần tử trong batch: 3\n",
            "Kiểu dữ liệu batch: <class 'tuple'>\n",
            "  Phần tử 0: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 1: type=<class 'torch.Tensor'>, shape=torch.Size([32, 27])\n",
            "  Phần tử 2: type=<class 'torch.Tensor'>, shape=torch.Size([32])\n",
            "\n",
            " Epoch 16 Summary:\n",
            "   Train Loss: 0.9985\n",
            "   Val Loss:   3.0421\n",
            "   Learning Rate: 0.000300\n",
            "   No improvement (3/3)\n",
            "\n",
            "Early stopping triggered after 16 epochs!\n",
            "   Best validation loss: 2.9856\n",
            "\n",
            " Training completed!\n",
            "Best validation loss: 2.9856\n",
            "Total epochs trained: 16\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 20 # Số epoch\n",
        "CLIP = 1\n",
        "\n",
        "train_losses, val_losses = train(model, train_iterator, valid_iterator,\n",
        "                                 criterion, optimizer,\n",
        "                                 N_EPOCHS, device, clip=CLIP,\n",
        "                                 teacher_forcing_ratio=0.5,\n",
        "                                 patience=3, model_path='best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2y2v9V2JOrxF",
      "metadata": {
        "id": "2y2v9V2JOrxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "7798c962-4b1e-4ebd-ade6-f11e3375ccf8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Vẽ biểu đồ Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Biểu đồ huấn luyện Model LSTM')\n",
        "plt.savefig('loss_chart.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "_5at0VL9Osow",
      "metadata": {
        "id": "_5at0VL9Osow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca644a9-cdae-4368-874b-6337f2e2c6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải lại tập Test để lấy ví dụ...\n",
            "--> Đã tải xong test_dataset với 1000 câu.\n",
            "Src: A mother and her young song enjoying a beautiful day outside.\n",
            "Trg: Une mère et son jeune fils profitant d'une belle journée dehors.\n",
            "Pred: une mère mère et sa jeune jeune jeune profitant d' une belle journée .\n"
          ]
        }
      ],
      "source": [
        "from src.dataset import TranslationDataset, build_vocab_and_tokenizers\n",
        "\n",
        "# 1. Lấy lại bộ từ điển và tokenizer\n",
        "# src_vocab, trg_vocab = build_vocab_and_tokenizers()\n",
        "\n",
        "# 2. Khởi tạo lại biến test_dataset thủ công\n",
        "print(\"Đang tải lại tập Test để lấy ví dụ...\")\n",
        "test_dataset = TranslationDataset(\n",
        "    'data/raw/test_2016_flickr.en',\n",
        "    'data/raw/test_2016_flickr.fr',\n",
        "    src_vocab, trg_vocab, src_tokenizer, trg_tokenizer\n",
        ")\n",
        "\n",
        "print(f\"--> Đã tải xong test_dataset với {len(test_dataset)} câu.\")\n",
        "# Load model tốt nhất\n",
        "checkpoint = torch.load('best_model.pth', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "\n",
        "def translate_sentence(sentence, src_tokenizer, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Tokenize\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = src_tokenizer(sentence)\n",
        "    else:\n",
        "        tokens = sentence\n",
        "\n",
        "    # 2. Convert to index\n",
        "    src_indexes = [src_vocab['<sos>']] + [src_vocab[t] for t in tokens] + [src_vocab['<eos>']]\n",
        "\n",
        "    # 3. Tensor hóa\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    src_len = torch.tensor([len(src_indexes)], dtype=torch.long).to(device)\n",
        "\n",
        "    # 4. Encode\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden, encoder_cell = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    # decoder hidden/cell init\n",
        "    hidden = encoder_hidden\n",
        "    cell = encoder_cell\n",
        "\n",
        "    # 5. Bắt đầu decode\n",
        "    trg_indexes = [trg_vocab['<sos>']]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).unsqueeze(0).to(device)  # [1,1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell, _ = model.decoder(\n",
        "                trg_tensor,      # [1,1]\n",
        "                hidden,          # hidden state\n",
        "                cell,            # cell state\n",
        "                encoder_outputs   # context cố định từ encoder\n",
        "            )\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.lookup_token(i) for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1]   # bỏ <sos> và <eos>\n",
        "\n",
        "\n",
        "# Thử dịch 1 câu trong tập test\n",
        "\n",
        "# 1. Chọn index\n",
        "example_idx = 10\n",
        "\n",
        "# 2. Lấy trực tiếp từ list chứa text thô (Raw text)\n",
        "src = test_dataset.src_data[example_idx].strip()\n",
        "trg = test_dataset.trg_data[example_idx].strip()\n",
        "\n",
        "print(f'Src: {src}')\n",
        "print(f'Trg: {trg}')\n",
        "\n",
        "# 3. Dịch\n",
        "translation = translate_sentence(src, src_tokenizer, model, device)\n",
        "\n",
        "print(f'Pred: {\" \".join(translation)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def translate_sentence_beam(\n",
        "    sentence,\n",
        "    src_tokenizer,\n",
        "    src_vocab,\n",
        "    trg_vocab,\n",
        "    model,\n",
        "    device,\n",
        "    beam_size=5,\n",
        "    max_len=50\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    # --- Encode ---\n",
        "    tokens = src_tokenizer(sentence.lower())\n",
        "    src_indexes = (\n",
        "        [src_vocab['<sos>']] +\n",
        "        [src_vocab[t] for t in tokens] +\n",
        "        [src_vocab['<eos>']]\n",
        "    )\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_len = torch.tensor([len(src_indexes)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    # --- Beam init ---\n",
        "    beams = [{\n",
        "        \"tokens\": [trg_vocab['<sos>']],\n",
        "        \"hidden\": hidden,\n",
        "        \"cell\": cell,\n",
        "        \"log_prob\": 0.0\n",
        "    }]\n",
        "\n",
        "    completed = []\n",
        "\n",
        "    # --- Decode ---\n",
        "    for _ in range(max_len):\n",
        "        new_beams = []\n",
        "\n",
        "        for beam in beams:\n",
        "            last_token = beam[\"tokens\"][-1]\n",
        "\n",
        "            if last_token == trg_vocab['<eos>']:\n",
        "                completed.append(beam)\n",
        "                continue\n",
        "\n",
        "            trg_tensor = torch.LongTensor([[last_token]]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output, hidden, cell, attn = model.decoder(\n",
        "                    trg_tensor,\n",
        "                    beam[\"hidden\"],\n",
        "                    beam[\"cell\"],\n",
        "                    encoder_outputs\n",
        "                )\n",
        "\n",
        "            log_probs = F.log_softmax(output, dim=1)\n",
        "            topk_log_probs, topk_ids = log_probs.topk(beam_size)\n",
        "\n",
        "            for i in range(beam_size):\n",
        "                new_beams.append({\n",
        "                    \"tokens\": beam[\"tokens\"] + [topk_ids[0, i].item()],\n",
        "                    \"hidden\": hidden,\n",
        "                    \"cell\": cell,\n",
        "                    \"log_prob\": beam[\"log_prob\"] + topk_log_probs[0, i].item()\n",
        "                })\n",
        "\n",
        "        beams = sorted(\n",
        "            new_beams,\n",
        "            key=lambda x: x[\"log_prob\"],\n",
        "            reverse=True\n",
        "        )[:beam_size]\n",
        "\n",
        "        if len(beams) == 0:\n",
        "            break\n",
        "\n",
        "    completed += beams\n",
        "    best = max(completed, key=lambda x: x[\"log_prob\"])\n",
        "\n",
        "    trg_tokens = [\n",
        "        trg_vocab.lookup_token(i)\n",
        "        for i in best[\"tokens\"]\n",
        "    ]\n",
        "\n",
        "    return trg_tokens[1:-1]\n"
      ],
      "metadata": {
        "id": "gGGWZldX8OYV"
      },
      "id": "gGGWZldX8OYV",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = test_dataset.src_data[10].strip()\n",
        "translation = translate_sentence_beam(\n",
        "    src,\n",
        "    src_tokenizer,\n",
        "    src_vocab,\n",
        "    trg_vocab,\n",
        "    model,\n",
        "    device,\n",
        "    beam_size=5\n",
        ")\n",
        "\n",
        "print(\"Pred:\", \" \".join(translation))"
      ],
      "metadata": {
        "id": "VHeRnrR-8Z9e",
        "outputId": "c56b98c4-bbbb-4cb3-e386-96c30ed8e169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VHeRnrR-8Z9e",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: une mère et son jeune jeune profitant d' une belle journée ensoleillée .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "MBSaCTD9OwR6",
      "metadata": {
        "id": "MBSaCTD9OwR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0a6341-60c6-40f6-85d0-19e931910ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tính toán BLEU trên 1000 câu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|██████████| 1000/1000 [00:14<00:00, 66.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BLEU score = 35.21\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_bleu(data, model, device, max_len=50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    # Chuyển model sang chế độ đánh giá\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Đang tính toán BLEU trên {len(data)} câu...\")\n",
        "    for i in tqdm(range(len(data)), desc=\"Translating\"):\n",
        "\n",
        "        # 1. Lấy câu gốc và câu đích dạng chuỗi\n",
        "        src_raw = data.src_data[i].strip()\n",
        "        trg_raw = data.trg_data[i].strip()\n",
        "\n",
        "        # 2. Model dịch và trả về list token\n",
        "        pred_trg = translate_sentence(src_raw, src_tokenizer, model, device, max_len)\n",
        "\n",
        "        # 3. Tokenize câu đích (Ground Truth)\n",
        "        if isinstance(trg_raw, str):\n",
        "            trg_tokenized = trg_tokenizer(trg_raw)\n",
        "        else:\n",
        "            trg_tokenized = list(trg_raw)\n",
        "\n",
        "        # --- Làm sạch (Filter) ---\n",
        "        ignore_tokens = [\"<sos>\", \"<eos>\", \"<pad>\", \"<unk>\"]\n",
        "\n",
        "        pred_trg_clean = [tok for tok in pred_trg if tok not in ignore_tokens]\n",
        "        trg_tokenized_clean = [tok for tok in trg_tokenized if tok not in ignore_tokens]\n",
        "\n",
        "        # 4. Thêm vào list theo đúng format torchtext yêu cầu\n",
        "        pred_trgs.append(pred_trg_clean)\n",
        "        trgs.append([trg_tokenized_clean])\n",
        "\n",
        "    # --- Tính BLEU ---\n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "score = calculate_bleu(test_dataset, model, device)\n",
        "print(f\"\\nBLEU score = {score*100:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}